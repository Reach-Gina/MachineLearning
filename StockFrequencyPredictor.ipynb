{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Final Project\n",
    "\n",
    "Gina Nguyen CS 6375\n",
    "\n",
    "## Introduction:\n",
    "This stock analysis algorithm aims to approximate a stock's \"sentiment\" through its google search. The popularity of a company on google searches can be found using google trends, which is access by the pytrends package. Furthmore, the google trend data ranges from 0 to 100, where the high the number is, the more popular the search is. \n",
    "\n",
    "In this project, I examine three company stocks, Johnson & Johnson (JNJ), Apple (AAPL), and Vox Royalty Corp (VOXR). Then each stock is analyzed with one regression model(a linear regression) and three different classifiers (SVM, naive bayes, and a neural network model). The goal of the regression is to predict the stock price while the goal of the classifier is to predict if the price will go up, down, or no change.\n",
    "\n",
    "Notes for this project:\n",
    "- The algorithm looks at the past 90 days.\n",
    "- JNJ and AAPL were chosen as stocks because it is own by well-known companies in two different fields, while VOXR was chosen at random from the following website (http://randomstocks.buckmaster.ca/)\n",
    "- How I imported financial information from yahoo finance (yfinance package): \n",
    "    - https://analyzingalpha.com/yfinance-python\n",
    "    - https://pypi.org/project/yfinance/\n",
    "- How I imported the change in gooogle searches from google trends (pytrends package): \n",
    "    - https://towardsdatascience.com/telling-stories-with-google-trends-using-pytrends-in-python-a11e5b8a177\\\n",
    "    - https://pypi.org/project/pytrends/\n",
    "- The inspiration for combining the stock history with google trends:\n",
    "    - https://medium.com/analytics-vidhya/how-to-pd-merge-two-data-frames-on-a-common-date-column-e7808d7ccaee\n",
    "- What the financial history and google trends looks like for JNJ:\n",
    "-   https://www.nasdaq.com/market-activity/stocks/jnj/historical\n",
    "-   https://trends.google.com/trends/explore?date=today%201-m&geo=US&q=%2Fm%2F07zl74p&hl=en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "from datetime import datetime\n",
    "from pytrends import dailydata\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class Stock:\n",
    "    def __init__(self, name, curr_date, past_months):\n",
    "        self.name = name #Name of the stock\n",
    "        self.curr_date = curr_date\n",
    "        self.past_months = past_months\n",
    "\n",
    "        #Getting the google trend data\n",
    "        trends = dailydata.get_daily_data(self.name, self.past_months.year, self.past_months.month, self.curr_date.year,self.curr_date.month)\n",
    "        #Note that for this project, we will be using the 3rd column, a.k.a. the \"monthly\", as the trend data\n",
    "        trends_monthly = trends[self.name + '_monthly']\n",
    "        self.trend = pd.DataFrame(trends_monthly)\n",
    "\n",
    "        #Getting the financial history\n",
    "        self.finance = yf.download(self.name, start=self.past_months, end=self.curr_date)\n",
    "\n",
    "        #Getting a merged dataset combining the stock history with the google trend data\n",
    "        self.trend.index = pd.to_datetime(self.trend.index)\n",
    "        self.finance.index = pd.to_datetime(self.finance.index)\n",
    "        self.merged = pd.merge(self.finance, self.trend, how='inner', left_index=True, right_index=True)\n",
    "    \n",
    "    def get_name(self):\n",
    "        return self.name\n",
    "    \n",
    "    def get_stock_info(self):\n",
    "        stock_info = yf.Ticker(self.name)\n",
    "        return stock_info\n",
    "\n",
    "    def get_trend(self):\n",
    "        return self.trend\n",
    "    \n",
    "    def recent_trend(self):\n",
    "        return self.get_trend().values[-1]\n",
    "    \n",
    "    def get_finan_hist(self):\n",
    "        return self.finance\n",
    "    \n",
    "    def recent_price(self):\n",
    "        return self.get_finan_hist().values[-1,3]\n",
    "    \n",
    "    def get_merged(self): #returns a dataframe containing both the stock info and the google trend data\n",
    "        return self.merged    \n",
    "\n",
    "def test_regression(X_train, Y_train, X_test, Y_test, model): #Gives the accuracy of a model\n",
    "    #Seeing how the model does on the training set\n",
    "    from sklearn.metrics import r2_score\n",
    "    def rmse(predictions, targets):\n",
    "            return np.sqrt(((predictions-targets) ** 2).mean())\n",
    "\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    rmse_train = rmse(y_pred_train, Y_train)\n",
    "    r2_train = r2_score(Y_train, y_pred_train)\n",
    "    print(\"Training RMSE = \" + str(rmse_train))\n",
    "    print(\"Training R2 = \" + str(r2_train))\n",
    "\n",
    "    #Seeing how the model does on the test set\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    rmse_test = rmse(y_pred_test, Y_test)\n",
    "    r2_test = r2_score(Y_test, y_pred_test)\n",
    "    print(\"Test RMSE = \" + str(rmse_test))\n",
    "    print(\"Test R2 = \" + str(r2_test))\n",
    "\n",
    "def test_classifier(X_train, Y_train, X_test, Y_test, model):\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.metrics import precision_score\n",
    "    from sklearn.metrics import recall_score\n",
    "    from sklearn.metrics import f1_score\n",
    "    \n",
    "    y_pred_train = model.predict(X_train)\n",
    "    accuracy = accuracy_score(y_pred_train, Y_train)\n",
    "    print(\"Training accuracy: \" + str(accuracy))\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_pred_test, Y_test)\n",
    "    print(\"Test accuracy: \" + str(accuracy))\n",
    "    \n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from sklearn.metrics import ConfusionMatrixDisplay\n",
    "    cm = confusion_matrix(Y_train, y_pred_train)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot()\n",
    "    plt.show()\n",
    "\n",
    "def implement_SVM(stock, both):\n",
    "    #SVM Model looking at all features\n",
    "    print(stock.get_name(), \"SVM model on all features: \")\n",
    "    #Splitting the dataset\n",
    "    X = both.drop(columns=['Close', 'Change'])\n",
    "    Y = both['Change']\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.3, random_state=42)\n",
    "    #Training the model\n",
    "    from sklearn.svm import SVC\n",
    "    svm_model = SVC()\n",
    "    svm_model.fit(X_train, Y_train)\n",
    "    #Viewing the accuracy of the model\n",
    "    test_classifier(X_train, Y_train, X_test, Y_test, svm_model)\n",
    "\n",
    "    #SVM Model based all features except the google trends:\n",
    "    print()\n",
    "    print(stock.get_name(), \"SVM on all features EXCEPT the google trend data: \")\n",
    "    #Splitting the dataset\n",
    "    X = both.drop(columns=['Close', 'Change', stock.get_name()+'_monthly', 'ChangeTrend'])\n",
    "    Y = both['Change']\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.3, random_state=42)\n",
    "    #Training the model\n",
    "    svm_model = SVC()\n",
    "    svm_model.fit(X_train, Y_train)\n",
    "    #Viewing the accuracy of the model\n",
    "    test_classifier(X_train, Y_train, X_test, Y_test, svm_model)\n",
    "\n",
    "    #SVM Model based all features only the google trends:\n",
    "    print()\n",
    "    print(stock.get_name(), \"SVM on ONLY the google trend data: \")\n",
    "    #Splitting the dataset\n",
    "    X = both[['ChangeTrend']]\n",
    "    Y = both['Change']\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.3, random_state=42)\n",
    "    #Training the model\n",
    "    svm_model = SVC()\n",
    "    svm_model.fit(X_train, Y_train)\n",
    "    #Viewing the accuracy of the model\n",
    "    test_classifier(X_train, Y_train, X_test, Y_test, svm_model)\n",
    "\n",
    "def implement_NB(stock, both):\n",
    "    #Naive Bayes Model looking at all features\n",
    "    print(stock.get_name(), \"Naive Bayes model on all features: \")\n",
    "    #Splitting the dataset\n",
    "    X = both.drop(columns=['Close', 'Change'])\n",
    "    Y = both['Change']\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.3, random_state=42)\n",
    "    #Training the model\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    bayes_model = GaussianNB()\n",
    "    bayes_model.fit(X_train, Y_train)\n",
    "    #Viewing the accuracy of the model\n",
    "    test_classifier(X_train, Y_train, X_test, Y_test, bayes_model)\n",
    "\n",
    "    #Naive Bayes Model Model based all features except the google trends:\n",
    "    print()\n",
    "    print(stock.get_name(), \"Naive Bayes model on all features EXCEPT the google trend data: \")\n",
    "    #Splitting the dataset\n",
    "    X = both.drop(columns=['Close', 'Change', stock.get_name()+'_monthly', 'ChangeTrend'])\n",
    "    Y = both['Change']\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.3, random_state=42)\n",
    "    #Training the model\n",
    "    bayes_model = GaussianNB()\n",
    "    bayes_model.fit(X_train, Y_train)\n",
    "    #Viewing the accuracy of the model\n",
    "    test_classifier(X_train, Y_train, X_test, Y_test, bayes_model)\n",
    "\n",
    "    #Naive Bayes Model Model based all features only the google trends:\n",
    "    print()\n",
    "    print(stock.get_name(), \"Naive Bayes model on ONLY the google trend data: \")\n",
    "    #Splitting the dataset\n",
    "    X = both[['ChangeTrend']]\n",
    "    Y = both['Change']\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.3, random_state=42)\n",
    "    #Training the model\n",
    "    bayes_model = GaussianNB()\n",
    "    bayes_model.fit(X_train, Y_train)\n",
    "    #Viewing the accuracy of the model\n",
    "    test_classifier(X_train, Y_train, X_test, Y_test, bayes_model)\n",
    "\n",
    "def implement_NN(stock, both):\n",
    "    #Neural Network Model looking at all features\n",
    "    print(stock.get_name(), \"Neural Network model on all features: \")\n",
    "    #Splitting the dataset\n",
    "    X = both.drop(columns=['Close', 'Change'])\n",
    "    Y = both['Change']\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.3, random_state=42)\n",
    "    #Training the model\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    neural_model = MLPClassifier()\n",
    "    neural_model.fit(X_train, Y_train)\n",
    "    #Viewing the accuracy of the model\n",
    "    test_classifier(X_train, Y_train, X_test, Y_test, neural_model)\n",
    "\n",
    "    #Neural Network Model Model based all features except the google trends:\n",
    "    print()\n",
    "    print(stock.get_name(), \"Neural Network model on all features EXCEPT the google trend data: \")\n",
    "    #Splitting the dataset\n",
    "    X = both.drop(columns=['Close', 'Change', stock.get_name()+'_monthly', 'ChangeTrend'])\n",
    "    Y = both['Change']\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.3, random_state=42)\n",
    "    #Training the model\n",
    "    neural_model = MLPClassifier()\n",
    "    neural_model.fit(X_train, Y_train)\n",
    "    #Viewing the accuracy of the model\n",
    "    test_classifier(X_train, Y_train, X_test, Y_test, neural_model)\n",
    "\n",
    "    #Neural Network Model Model based all features only the google trends:\n",
    "    print()\n",
    "    print(stock.get_name(), \"Neural Network model on ONLY the google trend data: \")\n",
    "    #Splitting the dataset\n",
    "    X = both[['ChangeTrend']]\n",
    "    Y = both['Change']\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.3, random_state=42)\n",
    "    #Training the model\n",
    "    neural_model = MLPClassifier()\n",
    "    neural_model.fit(X_train, Y_train)\n",
    "    #Viewing the accuracy of the model\n",
    "    test_classifier(X_train, Y_train, X_test, Y_test, neural_model)\n",
    "\n",
    "def implement_ADA(stock, both):\n",
    "    #AdaBoost Model looking at all features\n",
    "    print(stock.get_name(), \"AdaBoost model on all features: \")\n",
    "    #Splitting the dataset\n",
    "    X = both.drop(columns=['Close', 'Change'])\n",
    "    Y = both['Change']\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.3, random_state=42)\n",
    "    #Training the model\n",
    "    from sklearn.ensemble import AdaBoostClassifier\n",
    "    ada_model = AdaBoostClassifier()\n",
    "    ada_model.fit(X_train, Y_train)\n",
    "    #Viewing the accuracy of the model\n",
    "    test_classifier(X_train, Y_train, X_test, Y_test, ada_model)\n",
    "\n",
    "    #AdaBoost Model based all features except the google trends:\n",
    "    print()\n",
    "    print(stock.get_name(), \"AdaBoost on all features EXCEPT the google trend data: \")\n",
    "    #Splitting the dataset\n",
    "    X = both.drop(columns=['Close', 'Change', stock.get_name()+'_monthly', 'ChangeTrend'])\n",
    "    Y = both['Change']\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.3, random_state=42)\n",
    "    #Training the model\n",
    "    ada_model = AdaBoostClassifier()\n",
    "    ada_model.fit(X_train, Y_train)\n",
    "    #Viewing the accuracy of the model\n",
    "    test_classifier(X_train, Y_train, X_test, Y_test, ada_model)\n",
    "\n",
    "    #AdaBoost Model based all features only the google trends:\n",
    "    print()\n",
    "    print(stock.get_name(), \"AdaBoost on ONLY the google trend data: \")\n",
    "    #Splitting the dataset\n",
    "    X = both[['ChangeTrend']]\n",
    "    Y = both['Change']\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.3, random_state=42)\n",
    "    #Training the model\n",
    "    ada_model = AdaBoostClassifier()\n",
    "    ada_model.fit(X_train, Y_train)\n",
    "    #Viewing the accuracy of the model\n",
    "    test_classifier(X_train, Y_train, X_test, Y_test, ada_model)\n",
    "\n",
    "date_range = 90 #tells us how many days ago you want to look at data\n",
    "curr_date = datetime.now() #gets the current date\n",
    "past_months = datetime.fromtimestamp(curr_date.timestamp() - (date_range*24*60*60)) #gets the date of [date_range] days ago (date_range*hours*mins*secs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at Johnson and Johnson Stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing on Johnson & Johnson, whose stock name is JNJ:\n",
    "jnj = Stock(\"JNJ\", curr_date, past_months)\n",
    "print(\"Most recent google trend data for JNJ: \", jnj.recent_trend())\n",
    "print(\"Most recent stock price for JNJ: \", jnj.recent_price())\n",
    "\n",
    "#Viewing JNJ stock as a correlation matrix\n",
    "both_jnj = jnj.get_merged()\n",
    "correlation_matrix = both_jnj.corr().round(2)\n",
    "sns.heatmap(data=correlation_matrix, annot=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Regression Models\n",
    "\n",
    "Looking at the correlation matrix above, you can see the the google trend (a.k.a. \"JNJ_monthly\") has a low correlation with the other features. In comparison with the results of the linear regression below, the google trends low correlation seems to lower the regression accuracy. \n",
    "\n",
    "Why does this make sense? Because stock prices do not change as quickly as google trend searches and, importantly, stock prices tend to depend on the prior prices. Because of this, we also look at classifying models as well as regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JNJ Linear Regression model on all features: \n",
      "Training RMSE = 0.23608052897459428\n",
      "Training R2 = 0.9976929445745066\n",
      "Test RMSE = 0.33963443064389437\n",
      "Test R2 = 0.9951067418474061\n",
      "\n",
      "JNJ Linear Regression model on all features EXCEPT the google trend data: \n",
      "Training RMSE = 0.23721078591007025\n",
      "Training R2 = 0.9976708012204196\n",
      "Test RMSE = 0.337519179806825\n",
      "Test R2 = 0.9951675026890513\n"
     ]
    }
   ],
   "source": [
    "#Linear Regression Model looking at all features\n",
    "print(\"JNJ Linear Regression model on all features: \")\n",
    "#Splitting the dataset\n",
    "X = both_jnj.drop(columns=['Close'])\n",
    "Y = both_jnj['Close']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.3, random_state=42)\n",
    "#Training the model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lin_model = LinearRegression()\n",
    "lin_model.fit(X_train, Y_train)\n",
    "#Viewing the accuracy of the model\n",
    "test_regression(X_train, Y_train, X_test, Y_test, lin_model)\n",
    "\n",
    "#Linear Regression Model based all features except the google trends:\n",
    "print()\n",
    "print(\"JNJ Linear Regression model on all features EXCEPT the google trend data: \")\n",
    "#Splitting the dataset\n",
    "X = both_jnj.drop(columns=['Close', 'JNJ_monthly'])\n",
    "Y = both_jnj['Close']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.3, random_state=42)\n",
    "#Training the model\n",
    "lin_model_trend = LinearRegression()\n",
    "lin_model_trend.fit(X_train, Y_train)\n",
    "#Viewing the accuracy of the model\n",
    "test_regression(X_train, Y_train, X_test, Y_test, lin_model_trend)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on Classifier Models:\n",
    "\n",
    "Before we can use a classifier model, we need to determine what we are classifying. In this case, I would like to guess if a stock price is going to increase or decrease. Because of this, we are going to compare the \"current\" stock price with its previous, where an increase is classified as 1, a decrease is classified as -1, and no change in price is classified as 0. Furthermore, the google trend data is converted to \"a change in google trends\".\n",
    "\n",
    "When looking at the below results, you will find that look at only the google trend data has the best prediction on if a stock has a price increase/decrease. However, you will also notice that the accuracy is much lower than the regression. This is presumably because predicting if a stock price is going to increase/decrease is a difficult task. Only having a stocks financial history and its google trends result is NOT enough to tell the changes in price. However, since my predictions with google trends are more than 50%, I will mentally take this as a win."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding if the stock prices are increasing or decreasing and adding it to a column called \"Change\"\n",
    "both_jnj['Change'] = 0\n",
    "prev_row = None\n",
    "for index, row in both_jnj.iloc[1:].iterrows():\n",
    "    curr_price = row['Close']\n",
    "    if prev_row is None:\n",
    "        prev_row = curr_price\n",
    "    price_diff = curr_price - prev_row\n",
    "    if (price_diff > 0):\n",
    "        row['Change'] = 1 #Increased price\n",
    "    elif (price_diff < 0):\n",
    "        row['Change'] = -1 #Decreased price\n",
    "    else:\n",
    "        row['Change'] = 0 #No change\n",
    "    both_jnj.loc[index,'Change']=row['Change']\n",
    "    \n",
    "    prev_row = curr_price\n",
    "\n",
    "#Finding if the google trend is increasing or decreasing and adding it to a column called \"ChangeTrend\"\n",
    "both_jnj['ChangeTrend'] = 0\n",
    "prev_row = None\n",
    "for index, row in both_jnj.iloc[1:].iterrows():\n",
    "    curr_trend = row['JNJ_monthly']\n",
    "    if prev_row is None:\n",
    "        prev_row = curr_trend\n",
    "    trend_diff = curr_trend - prev_row\n",
    "    if (trend_diff > 0):\n",
    "        row['ChangeTrend'] = 1 #Increased price\n",
    "    elif (trend_diff < 0):\n",
    "        row['ChangeTrend'] = -1 #Decreased price\n",
    "    else:\n",
    "        row['ChangeTrend'] = 0 #No change\n",
    "    both_jnj.loc[index,'ChangeTrend']=row['ChangeTrend']\n",
    "    \n",
    "    prev_row = curr_trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM\n",
    "implement_SVM(jnj, both_jnj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes\n",
    "implement_NB(jnj, both_jnj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neural Network\n",
    "implement_NB(jnj, both_jnj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AdaBoost\n",
    "implement_ADA(jnj, both_jnj) #I was smart this time and wrote a function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at Apple Stock\n",
    "So far, we've looked at the Johnson and Johnson stock (JNJ) which belongs to a healthcare and pharmeceuticals company. In contrast, Apple stock (AAPL) belongs to a tech company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing on Apple, whose stock name is AAPL\n",
    "aapl = Stock(\"AAPL\", curr_date, past_months)\n",
    "print(\"Most recent google trend data for AAPL: \", aapl.recent_trend())\n",
    "print(\"Most recent stock price for AAPL: \", aapl.recent_price())\n",
    "\n",
    "#Viewing AAPL Stock as a correlation matrix\n",
    "both_aapl = aapl.get_merged()\n",
    "correlation_matrix = both_aapl.corr().round(2)\n",
    "sns.heatmap(data=correlation_matrix, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear Regression Model looking at all features\n",
    "print(\"AAPL Linear Regression model on all features: \")\n",
    "#Splitting the dataset\n",
    "X = both_aapl.drop(columns=['Close'])\n",
    "Y = both_aapl['Close']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.3, random_state=42)\n",
    "#Training the model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lin_model = LinearRegression()\n",
    "lin_model.fit(X_train, Y_train)\n",
    "#Viewing the accuracy of the model\n",
    "test_regression(X_train, Y_train, X_test, Y_test, lin_model)\n",
    "\n",
    "#Linear Regression Model based all features except the google trends:\n",
    "print()\n",
    "print(\"AAPL Linear Regression model on all features EXCEPT the google trend data: \")\n",
    "#Splitting the dataset\n",
    "X = both_aapl.drop(columns=['Close', 'AAPL_monthly'])\n",
    "Y = both_aapl['Close']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.3, random_state=42)\n",
    "#Training the model\n",
    "lin_model_trend = LinearRegression()\n",
    "lin_model_trend.fit(X_train, Y_train)\n",
    "#Viewing the accuracy of the model\n",
    "test_regression(X_train, Y_train, X_test, Y_test, lin_model_trend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding if the stock prices are increasing or decreasing and adding it to a column called \"Change\"\n",
    "both_aapl['Change'] = 0\n",
    "prev_row = None\n",
    "for index, row in both_aapl.iloc[1:].iterrows():\n",
    "    curr_price = row['Close']\n",
    "    if prev_row is None:\n",
    "        prev_row = curr_price\n",
    "    price_diff = curr_price - prev_row\n",
    "    if (price_diff > 0):\n",
    "        row['Change'] = 1 #Increased price\n",
    "    elif (price_diff < 0):\n",
    "        row['Change'] = -1 #Decreased price\n",
    "    else:\n",
    "        row['Change'] = 0 #No change\n",
    "    both_aapl.loc[index,'Change']=row['Change']\n",
    "    \n",
    "    prev_row = curr_price\n",
    "\n",
    "#Finding if the google trend is increasing or decreasing and adding it to a column called \"ChangeTrend\"\n",
    "both_aapl['ChangeTrend'] = 0\n",
    "prev_row = None\n",
    "for index, row in both_aapl.iloc[1:].iterrows():\n",
    "    curr_trend = row['AAPL_monthly']\n",
    "    if prev_row is None:\n",
    "        prev_row = curr_trend\n",
    "    trend_diff = curr_trend - prev_row\n",
    "    if (trend_diff > 0):\n",
    "        row['ChangeTrend'] = 1 #Increased price\n",
    "    elif (trend_diff < 0):\n",
    "        row['ChangeTrend'] = -1 #Decreased price\n",
    "    else:\n",
    "        row['ChangeTrend'] = 0 #No change\n",
    "    both_aapl.loc[index,'ChangeTrend']=row['ChangeTrend']\n",
    "    \n",
    "    prev_row = curr_trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM\n",
    "implement_SVM(aapl, both_aapl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes\n",
    "implement_NB(aapl, both_aapl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neural Network Model\n",
    "implement_NN(aapl, both_aapl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AdaBoost\n",
    "implement_ADA(aapl, both_aapl)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at VOXR Stock (from a presumably less known company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing on VOXR Stock\n",
    "voxr = Stock(\"VOXR\", curr_date, past_months)\n",
    "print(\"Most recent google trend data for VOXR: \", voxr.recent_trend())\n",
    "print(\"Most recent stock price for VOXR: \", voxr.recent_price())\n",
    "\n",
    "#Viewing AAPL Stock as a correlation matrix\n",
    "both_voxr = voxr.get_merged()\n",
    "correlation_matrix = both_voxr.corr().round(2)\n",
    "sns.heatmap(data=correlation_matrix, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear Regression Model looking at all features\n",
    "print(\"VOXR Linear Regression model on all features: \")\n",
    "#Splitting the dataset\n",
    "X = both_voxr.drop(columns=['Close'])\n",
    "Y = both_voxr['Close']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.3, random_state=42)\n",
    "#Training the model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lin_model = LinearRegression()\n",
    "lin_model.fit(X_train, Y_train)\n",
    "#Viewing the accuracy of the model\n",
    "test_regression(X_train, Y_train, X_test, Y_test, lin_model)\n",
    "\n",
    "#Linear Regression Model based all features except the google trends:\n",
    "print()\n",
    "print(\"VOXR Linear Regression model on all features EXCEPT the google trend data: \")\n",
    "#Splitting the dataset\n",
    "X = both_voxr.drop(columns=['Close', 'VOXR_monthly'])\n",
    "Y = both_voxr['Close']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.3, random_state=42)\n",
    "#Training the model\n",
    "lin_model_trend = LinearRegression()\n",
    "lin_model_trend.fit(X_train, Y_train)\n",
    "#Viewing the accuracy of the model\n",
    "test_regression(X_train, Y_train, X_test, Y_test, lin_model_trend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding if the stock prices are increasing or decreasing and adding it to a column called \"Change\"\n",
    "both_voxr['Change'] = 0\n",
    "prev_row = None\n",
    "for index, row in both_voxr.iloc[1:].iterrows():\n",
    "    curr_price = row['Close']\n",
    "    if prev_row is None:\n",
    "        prev_row = curr_price\n",
    "    price_diff = curr_price - prev_row\n",
    "    if (price_diff > 0):\n",
    "        row['Change'] = 1 #Increased price\n",
    "    elif (price_diff < 0):\n",
    "        row['Change'] = -1 #Decreased price\n",
    "    else:\n",
    "        row['Change'] = 0 #No change\n",
    "    both_voxr.loc[index,'Change']=row['Change']\n",
    "    \n",
    "    prev_row = curr_price\n",
    "\n",
    "#Finding if the google trend is increasing or decreasing and adding it to a column called \"ChangeTrend\"\n",
    "both_voxr['ChangeTrend'] = 0\n",
    "prev_row = None\n",
    "for index, row in both_voxr.iloc[1:].iterrows():\n",
    "    curr_trend = row['VOXR_monthly']\n",
    "    if prev_row is None:\n",
    "        prev_row = curr_trend\n",
    "    trend_diff = curr_trend - prev_row\n",
    "    if (trend_diff > 0):\n",
    "        row['ChangeTrend'] = 1 #Increased price\n",
    "    elif (trend_diff < 0):\n",
    "        row['ChangeTrend'] = -1 #Decreased price\n",
    "    else:\n",
    "        row['ChangeTrend'] = 0 #No change\n",
    "    both_voxr.loc[index,'ChangeTrend']=row['ChangeTrend']\n",
    "    \n",
    "    prev_row = curr_trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM Model\n",
    "implement_SVM(voxr, both_voxr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes Model\n",
    "implement_NB(voxr, both_voxr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neural Network Model\n",
    "implement_NN(voxr, both_voxr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AdaBoost\n",
    "implement_ADA(voxr, both_voxr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
